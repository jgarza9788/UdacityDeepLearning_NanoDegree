{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Section 1 \r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1 \r\n",
    "Environments and Packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Environments and Packages\r\n",
    "create an environment\r\n",
    "```CMD\r\n",
    "conda create -n <NAME> python=<version>\r\n",
    "```\r\n",
    "deleting environment\r\n",
    "```CMD\r\n",
    "conda env remove -n ENV_NAME\r\n",
    "```\r\n",
    "activate an environemtn\r\n",
    "```CMD\r\n",
    "activate <NAME> \r\n",
    "```\r\n",
    "deactivate an environemtn\r\n",
    "```CMD\r\n",
    "deactivate <NAME> \r\n",
    "```\r\n",
    "list environments\r\n",
    "```CMD\r\n",
    "conda info --envs\r\n",
    "```\r\n",
    "Install packages\r\n",
    "```CMD\r\n",
    "conda install PACKAGE_NAME\r\n",
    "```\r\n",
    "remove package\r\n",
    "```CMD\r\n",
    "conda remove PACKAGE_NAME\r\n",
    "```\r\n",
    "update package\r\n",
    "```CMD\r\n",
    "conda update package_name\r\n",
    "```\r\n",
    "search packages\r\n",
    "```CMD\r\n",
    "conda search '*beautifulsoup*'\r\n",
    "```\r\n",
    "list packages\r\n",
    "```CMD\r\n",
    "conda list\r\n",
    "```\r\n",
    "create and add packages to environment\r\n",
    "```CMD\r\n",
    "conda create -n env_name [python=X.X] [LIST_OF_PACKAGES]\r\n",
    "```\r\n",
    "exporting environment\r\n",
    "```CMD\r\n",
    "conda env export\r\n",
    "```\r\n",
    "```CMD\r\n",
    "conda env export > environment.yaml\r\n",
    "```\r\n",
    "```CMD\r\n",
    "conda env create -f environment.yaml \r\n",
    "######## create an environment with the name environment.yaml\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2\r\n",
    "Style Transfer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### links to code\r\n",
    "\r\n",
    "Style Transfer  \r\n",
    "https://github.com/lengstrom/fast-style-transfer\r\n",
    "\r\n",
    "Checkpoint files\r\n",
    "https://video.udacity-data.com/topher/2017/January/587d1865_rain-princess/rain-princess.ckpt\r\n",
    "https://video.udacity-data.com/topher/2017/January/588aa800_la-muse/la-muse.ckpt\r\n",
    "https://video.udacity-data.com/topher/2017/January/588aa846_udnie/udnie.ckpt\r\n",
    "https://video.udacity-data.com/topher/2017/January/588aa883_scream/scream.ckpt\r\n",
    "https://video.udacity-data.com/topher/2017/January/588aa89d_wave/wave.ckpt\r\n",
    "https://video.udacity-data.com/topher/2017/January/588aa8b6_wreck/wreck.ckpt"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### how to use\r\n",
    "1. download the github folder (and unzip)\r\n",
    "2. download the ckpt files and move them inside the github folder\r\n",
    "\r\n",
    "conda create -n style-transfer python=3\r\n",
    "conda activate style-transfer\r\n",
    "conda install tensorflow scipy pillow\r\n",
    "pip install moviepy\r\n",
    "python -c \"import imageio; imageio.plugins.ffmpeg.download()\" #this might not work\r\n",
    "\r\n",
    "\r\n",
    "1. activate style-transfer\r\n",
    "2. cd to directory\r\n",
    "3. run python evaluation script\r\n",
    "* checkpoint file (pre-trained ai)\r\n",
    "* input image \r\n",
    "* output image\r\n",
    "\r\n",
    "activate style-transfer\r\n",
    "\r\n",
    "cd .\\github\\UdacityDeepLearning_NanoDegree\\1_neural_networks\\fast-style-transfer-master\r\n",
    "\r\n",
    "python evaluate.py --checkpoint ./rain-princess.ckpt --in-path ./examples/content/memoji.png --out-path ./output_image.jpg\r\n",
    "\r\n",
    "\r\n",
    "python evaluate.py --checkpoint ./rain-princess.ckpt --in-path <path_to_input_file> --out-path ./output_image.jpg\r\n",
    "\r\n",
    "python evaluate.py --checkpoint ./wave.ckpt --in-path ./examples/content/memoji.png  --out-path ./output_image0.jpg\r\n",
    "python evaluate.py --checkpoint ./udnie.ckpt --in-path ./examples/content/memoji.png  --out-path ./output_image1.jpg\r\n",
    "python evaluate.py --checkpoint ./la-muse.ckpt --in-path ./memoji.png  --out-path ./output_image2.jpg\r\n",
    "python evaluate.py --checkpoint ./scream.ckpt --in-path ./examples/content/memoji.png  --out-path ./output_image3.jpg\r\n",
    "\r\n",
    "cd fast-style-transfer\r\n",
    "python evaluate.py --checkpoint la-muse.ckpt --in-path memoji.png  --out-path output_image2.jpg\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3\r\n",
    "flappy bird!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Flappy Bird\r\n",
    "link\r\n",
    "https://github.com/yenchenlin/DeepLearningFlappyBird\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```CMD\r\n",
    "conda create --name=flappybird python=3.5\r\n",
    "\r\n",
    "activate flappybird\r\n",
    "\r\n",
    "conda install opencv\r\n",
    "conda install pygame\r\n",
    "pip install tensorflow==0.12\r\n",
    "\r\n",
    "\r\n",
    "git clone https://github.com/yenchenlin/DeepLearningFlappyBird.git\r\n",
    "###### cd to it\r\n",
    "\r\n",
    "python deep_q_network.py\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 4\r\n",
    "Matrix Math"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scalars\r\n",
    "a single number\r\n",
    "1\r\n",
    "2.8\r\n",
    "3.1\r\n",
    "\r\n",
    "### Vector\r\n",
    "a row or column of numbers\r\n",
    "[1,2,3]\r\n",
    "[\r\n",
    "    1,\r\n",
    "    2,\r\n",
    "    3,\r\n",
    "]\r\n",
    "\r\n",
    "### Matrices\r\n",
    "rows and columns of numbers\r\n",
    "[\r\n",
    "    [1,2,3],\r\n",
    "    [1,2,3],\r\n",
    "    [1,2,3],\r\n",
    "]\r\n",
    "\r\n",
    "### Tensors\r\n",
    "any n-dimensional collection of values\r\n",
    "Scalars, Vectors, and Matrices\r\n",
    "\r\n",
    "[\r\n",
    "    [1,2,3],\r\n",
    "    [1,2,3],\r\n",
    "    [1,2,3],\r\n",
    "]\r\n",
    "\r\n",
    "[\r\n",
    "    [A01,A02,A03],\r\n",
    "    [A11,A12,A13],\r\n",
    "    [A21,A22,A23],\r\n",
    "]\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "### matrics math\r\n",
    "```\r\n",
    "2 + [[1,2],[3,4]] = [[1+2,2+2],[3+2,4+2]] = [[3,4],[5,6]]\r\n",
    "```\r\n",
    "add two to each item in the matrix ^\r\n",
    "\r\n",
    "#### add matrices\r\n",
    "\r\n",
    "[[1,2],[3,4]] + [[1,2],[3,4]] = [[2,3],[6,8]] \r\n",
    "\r\n",
    "* both needs to be the same size\r\n",
    "2x2 and 2x2 âœ…\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#### dot products\r\n",
    "https://www.youtube.com/watch?v=8jtk8BzBdj8&t=282s\r\n",
    "\r\n",
    "https://en.wikipedia.org/wiki/Dot_product\r\n",
    "\r\n",
    "rows * columns\r\n",
    "the number of rows need to equal the number of columns.\r\n",
    "aka the numbers on the inside need to be the same.\r\n",
    "\r\n",
    "2x3 * 3x2 âœ…\r\n",
    "2x2 * 3x3 â­•\r\n",
    "\r\n",
    "order matters in dot products\r\n",
    "\r\n",
    "Important Reminders About Matrix Multiplication\r\n",
    "* The number of columns in the left matrix must equal the number of rows in the right matrix.\r\n",
    "* The answer matrix always has the same number of rows as the left matrix and the same number of columns as the right matrix.\r\n",
    "* Order matters. Multiplying Aâ€¢B is not the same as multiplying Bâ€¢A.\r\n",
    "* Data in the left matrix should be arranged as rows., while data in the right matrix should be arranged as columns.\r\n",
    "\r\n",
    "\r\n",
    "#### Transponse\r\n",
    "swapping rows and columns\r\n",
    "\r\n",
    "[\r\n",
    "    [1,2],\r\n",
    "    [3,4]\r\n",
    "]\r\n",
    "\r\n",
    ".Transpose() \r\n",
    "or \r\n",
    ".T\r\n",
    "\r\n",
    "[\r\n",
    "    [1,3],\r\n",
    "    [2,4]\r\n",
    "]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Use the numpy library\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "def prepare_inputs(inputs):\r\n",
    "    # TODO: create a 2-dimensional ndarray from the given 1-dimensional list;\r\n",
    "    #       assign it to input_array\r\n",
    "    # print(inputs)\r\n",
    "    input_array = np.array(inputs).reshape(1,len(inputs))\r\n",
    "\r\n",
    "    # print(input_array)\r\n",
    "\r\n",
    "    # TODO: find the minimum value in input_array and subtract that\r\n",
    "    #       value from all the elements of input_array. Store the\r\n",
    "    #       result in inputs_minus_min\r\n",
    "    inputs_minus_min = input_array - input_array.min()\r\n",
    "\r\n",
    "    # TODO: find the maximum value in inputs_minus_min and divide\r\n",
    "    #       all of the values in inputs_minus_min by the maximum value.\r\n",
    "    #       Store the results in inputs_div_max.\r\n",
    "    inputs_div_max = inputs_minus_min / inputs_minus_min.max()\r\n",
    "\r\n",
    "    # return the three arrays we've created\r\n",
    "    return input_array, inputs_minus_min, inputs_div_max\r\n",
    "    \r\n",
    "\r\n",
    "def multiply_inputs(m1, m2):\r\n",
    "    # TODO: Check the shapes of the matrices m1 and m2. \r\n",
    "    #       m1 and m2 will be ndarray objects.\r\n",
    "    #\r\n",
    "    #       Return False if the shapes cannot be used for matrix\r\n",
    "    #       multiplication. You may not use a transpose\r\n",
    "    pass\r\n",
    "    print(\"m1.shape\",m1.shape)\r\n",
    "    print(\"m2.shape\",m2.shape)\r\n",
    "\r\n",
    "    print(m1.shape[1], m2.shape[0])\r\n",
    "    print(m1.shape[0], m2.shape[1])\r\n",
    "\r\n",
    "    dot = None\r\n",
    "    if m1.shape[1] == m2.shape[0]:\r\n",
    "        dot =  np.dot(m1,m2)\r\n",
    "    elif m1.shape[0]== m2.shape[1]:\r\n",
    "        dot = np.dot(m2,m1)\r\n",
    "    else:\r\n",
    "        return False\r\n",
    "\r\n",
    "\r\n",
    "    # TODO: If you have not returned False, then calculate the matrix product\r\n",
    "    #       of m1 and m2 and return it. Do not use a transpose,\r\n",
    "    #       but you swap their order if necessary\r\n",
    "    pass\r\n",
    "\r\n",
    "    return dot\r\n",
    "    \r\n",
    "\r\n",
    "def find_mean(values):\r\n",
    "    # TODO: Return the average of the values in the given Python list\r\n",
    "    pass\r\n",
    "    return np.array(values).mean()\r\n",
    "\r\n",
    "\r\n",
    "input_array, inputs_minus_min, inputs_div_max = prepare_inputs([-1,2,7])\r\n",
    "# print('input_array',input_array)\r\n",
    "# print('inputs_minus_min',inputs_minus_min)\r\n",
    "# print('inputs_div_max',inputs_div_max)\r\n",
    "\r\n",
    "print(\"Input as Array: {}\".format(input_array))\r\n",
    "print(\"Input minus min: {}\".format(inputs_minus_min))\r\n",
    "print(\"Input  Array: {}\".format(inputs_div_max))\r\n",
    "\r\n",
    "print(\"Multiply 1:\\n{}\".format(multiply_inputs(np.array([[1,2,3],[4,5,6]]), np.array([[1],[2],[3],[4]]))))\r\n",
    "print(\"Multiply 2:\\n{}\".format(multiply_inputs(np.array([[1,2,3],[4,5,6]]), np.array([[1],[2],[3]]))))\r\n",
    "print(\"Multiply 3:\\n{}\".format(multiply_inputs(np.array([[1,2,3],[4,5,6]]), np.array([[1,2]]))))\r\n",
    "\r\n",
    "print(\"Mean == {}\".format(find_mean([1,3,4])))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input as Array: [[-1  2  7]]\n",
      "Input minus min: [[0 3 8]]\n",
      "Input  Array: [[0.    0.375 1.   ]]\n",
      "m1.shape (2, 3)\n",
      "m2.shape (4, 1)\n",
      "3 4\n",
      "2 1\n",
      "Multiply 1:\n",
      "False\n",
      "m1.shape (2, 3)\n",
      "m2.shape (3, 1)\n",
      "3 3\n",
      "2 1\n",
      "Multiply 2:\n",
      "[[14]\n",
      " [32]]\n",
      "m1.shape (2, 3)\n",
      "m2.shape (1, 2)\n",
      "3 1\n",
      "2 2\n",
      "Multiply 3:\n",
      "[[ 9 12 15]]\n",
      "Mean == 2.6666666666666665\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Section 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1\r\n",
    "What is Deep Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What is Deep Learning\r\n",
    "\r\n",
    "it is a neural network\r\n",
    "a computer program and simulates the neurons in the brain \r\n",
    "\r\n",
    "this type of program and learn\r\n",
    "\r\n",
    "it can be used for:\r\n",
    "* classification\r\n",
    "* self driving cars\r\n",
    "* video games\r\n",
    "* finance \r\n",
    "* etc\r\n",
    "\r\n",
    "### Perceptron\r\n",
    "the neuron of the neural network\r\n",
    "(like in the brain)\r\n",
    "\r\n",
    "2*Test + 1 * Grades -18 = 0\r\n",
    "W*Test + 1 * Grades - 18 * B = 0\r\n",
    "\r\n",
    "W = weight\r\n",
    "B = bias\r\n",
    "\r\n",
    "Wx + B >= 0 \r\n",
    "sum(Xi * Wi) + B >= 0\r\n",
    "\r\n",
    "step function ... the value to Y or N\r\n",
    "\r\n",
    "(1.5 * 7) + (1 * 6) - 18 \r\n",
    "\r\n",
    "\r\n",
    "### Perceptrons as Logical Operators\r\n",
    "\r\n",
    "#### AND\r\n",
    "2 inputs\r\n",
    "true, true => true\r\n",
    "true, false => false\r\n",
    "false, true => false\r\n",
    "false, false => false\r\n",
    "\r\n",
    "1,1=>1\r\n",
    "1,0=>0\r\n",
    "0,1=>0\r\n",
    "0,0=>0\r\n",
    "\r\n",
    "#### OR\r\n",
    "1,1=>1\r\n",
    "1,0=>1\r\n",
    "0,1=>1\r\n",
    "0,0=>0\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "# TODO: Set weight1, weight2, and bias\r\n",
    "weight1 = 1\r\n",
    "weight2 = 1\r\n",
    "bias = -2\r\n",
    "\r\n",
    "# 1ð‘¥+1ð‘¦âˆ’2=0\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# DON'T CHANGE ANYTHING BELOW\r\n",
    "# Inputs and outputs\r\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\r\n",
    "correct_outputs = [False, False, False, True]\r\n",
    "outputs = []\r\n",
    "\r\n",
    "# Generate and check output\r\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\r\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\r\n",
    "    output = int(linear_combination >= 0)\r\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\r\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\r\n",
    "\r\n",
    "# Print output\r\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\r\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\r\n",
    "if not num_wrong:\r\n",
    "    print('Nice!  You got it all correct.\\n')\r\n",
    "else:\r\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\r\n",
    "print(output_frame.to_string(index=False))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                    -2                    0          Yes\n",
      "       0          1                    -1                    0          Yes\n",
      "       1          0                    -1                    0          Yes\n",
      "       1          1                     0                    1          Yes\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "# TODO: Set weight1, weight2, and bias\r\n",
    "weight1 = 0\r\n",
    "weight2 = -1\r\n",
    "bias = +0.5\r\n",
    "\r\n",
    "# 0ð‘¥ -1ð‘¦ +0.5 =0\r\n",
    "\r\n",
    "\r\n",
    "# DON'T CHANGE ANYTHING BELOW\r\n",
    "# Inputs and outputs\r\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\r\n",
    "correct_outputs = [True, False, True, False]\r\n",
    "outputs = []\r\n",
    "\r\n",
    "# Generate and check output\r\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\r\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\r\n",
    "    output = int(linear_combination >= 0)\r\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\r\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\r\n",
    "\r\n",
    "# Print output\r\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\r\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\r\n",
    "if not num_wrong:\r\n",
    "    print('Nice!  You got it all correct.\\n')\r\n",
    "else:\r\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\r\n",
    "print(output_frame.to_string(index=False))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                   0.5                    1          Yes\n",
      "       0          1                  -0.5                    0          Yes\n",
      "       1          0                   0.5                    1          Yes\n",
      "       1          1                  -0.5                    0          Yes\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### we can make percentions that build themselves\r\n",
    "\r\n",
    "line: \r\n",
    "3x + 4y - 10 = 0 \r\n",
    "\r\n",
    "point:\r\n",
    "(4,5)\r\n",
    "\r\n",
    "Learn Rate:\r\n",
    "0.1\r\n",
    "\r\n",
    "4 * 0.1 = 0.4  \r\n",
    "5 * 0.1 = 0.5  \r\n",
    "1 * 0.1 = 0.1  \r\n",
    "```\r\n",
    "    3    4  -10\r\n",
    "- 0.4  0.5  0.1\r\n",
    "_______________\r\n",
    "2.6  3.5  -10.1\r\n",
    "```\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "\r\n",
    "x1 = 3\r\n",
    "x2 = 4\r\n",
    "b = -10\r\n",
    "point = [1,1,1]\r\n",
    "lr = 0.1\r\n",
    "\r\n",
    "count = 0 \r\n",
    "\r\n",
    "while (x1*point[0]) + (x2*point[1]) + (b*point[2]) <= 0:\r\n",
    "    x1 += (point[0]*lr)\r\n",
    "    x2 += (point[1]*lr)\r\n",
    "    b += (point[2]*lr)\r\n",
    "    print( str(x1) + 'x + ' + str(x2) + 'y + ' + str(b) +  ' = 0')\r\n",
    "    count += 1\r\n",
    "print(count-1)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.1x + 4.1y + -9.9 = 0\n",
      "3.2x + 4.199999999999999y + -9.8 = 0\n",
      "3.3000000000000003x + 4.299999999999999y + -9.700000000000001 = 0\n",
      "3.4000000000000004x + 4.399999999999999y + -9.600000000000001 = 0\n",
      "3.5000000000000004x + 4.499999999999998y + -9.500000000000002 = 0\n",
      "3.6000000000000005x + 4.599999999999998y + -9.400000000000002 = 0\n",
      "3.7000000000000006x + 4.6999999999999975y + -9.300000000000002 = 0\n",
      "3.8000000000000007x + 4.799999999999997y + -9.200000000000003 = 0\n",
      "3.900000000000001x + 4.899999999999997y + -9.100000000000003 = 0\n",
      "4.000000000000001x + 4.9999999999999964y + -9.000000000000004 = 0\n",
      "4.1000000000000005x + 5.099999999999996y + -8.900000000000004 = 0\n",
      "10\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perception Algorithm\r\n",
    "\r\n",
    "1. start with random weights\r\n",
    "2.  for each false point (misclassified)\r\n",
    "    * 2.1 if prediction = 0\r\n",
    "        for i = 1 ... n\r\n",
    "            change wi + axi\r\n",
    "        change b to b + a\r\n",
    "    * 2.2 if prediction = 1\r\n",
    "        for i = 1 ..n\r\n",
    "            change w1 - ax\r\n",
    "        change b to b - a\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "import numpy as np\r\n",
    "from math import copysign \r\n",
    "# Setting the random seed, feel free to change it and see different solutions.\r\n",
    "np.random.seed(42)\r\n",
    "\r\n",
    "def stepFunction(t):\r\n",
    "    if t >= 0:\r\n",
    "        return 1\r\n",
    "    return 0\r\n",
    "\r\n",
    "def prediction(X, W, b):\r\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])\r\n",
    "\r\n",
    "# TODO: Fill in the code below to implement the perceptron trick.\r\n",
    "# The function should receive as inputs the data X, the labels y,\r\n",
    "# the weights W (as an array), and the bias b,\r\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\r\n",
    "# and return W and b.\r\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\r\n",
    "    # Fill in code\r\n",
    "\r\n",
    "    for index, x in enumerate(X):\r\n",
    "        # p or y_hat ... is the equation and the stepFunction (activation function)\r\n",
    "        p = prediction(x,W,b) \r\n",
    "\r\n",
    "        #if we should have got a 1, but we have a 0...we need to add\r\n",
    "        if y[index]-p == 1:\r\n",
    "            W[0][0] += (x[0]*learn_rate)\r\n",
    "            W[1][0] += (x[1]*learn_rate)\r\n",
    "            b += (1*learn_rate)\r\n",
    "        #if we should have got a 0, but we have a 1...we need to subtract\r\n",
    "        if y[index]-p == -1:\r\n",
    "            W[0][0] -= (x[0]*learn_rate)\r\n",
    "            W[1][0] -= (x[1]*learn_rate)\r\n",
    "            b -= (1*learn_rate)\r\n",
    "\r\n",
    "    return W, b\r\n",
    "\r\n",
    "\r\n",
    "_X = [[ 0.78051,-0.063669 ],\r\n",
    "[ 0.28774,0.29139  ],\r\n",
    "[ 0.40714,0.17878  ],\r\n",
    "[ 0.2923, 0.4217   ],\r\n",
    "[ 0.50922,0.35256  ],\r\n",
    "[ 0.27785,0.10802  ],\r\n",
    "[ 0.27527,0.33223  ],\r\n",
    "[ 0.43999,0.31245  ],\r\n",
    "[ 0.33557,0.42984  ],\r\n",
    "[ 0.23448,0.24986  ],\r\n",
    "[ 0.0084492, 0.13658  ],\r\n",
    "[ 0.12419,0.33595  ],\r\n",
    "[ 0.25644,0.42624  ],\r\n",
    "[ 0.4591, 0.40426  ],\r\n",
    "[ 0.44547,0.45117  ],\r\n",
    "[ 0.42218,0.20118  ],\r\n",
    "[ 0.49563,0.21445  ],\r\n",
    "[ 0.30848,0.24306  ],\r\n",
    "[ 0.39707,0.44438  ],\r\n",
    "[ 0.32945,0.39217  ],\r\n",
    "[ 0.40739,0.40271  ],\r\n",
    "[ 0.3106, 0.50702  ],\r\n",
    "[ 0.49638,0.45384  ],\r\n",
    "[ 0.10073,0.32053  ],\r\n",
    "[ 0.69907,0.37307  ],\r\n",
    "[ 0.29767,0.69648  ],\r\n",
    "[ 0.15099,0.57341  ],\r\n",
    "[ 0.16427,0.27759  ],\r\n",
    "[ 0.33259,0.055964 ],\r\n",
    "[ 0.53741,0.28637  ],\r\n",
    "[ 0.19503,0.36879  ],\r\n",
    "[ 0.40278,0.035148 ],\r\n",
    "[ 0.21296,0.55169  ],\r\n",
    "[ 0.48447,0.56991  ],\r\n",
    "[ 0.25476,0.34596  ],\r\n",
    "[ 0.21726,0.28641  ],\r\n",
    "[ 0.67078,0.46538  ],\r\n",
    "[ 0.3815, 0.4622   ],\r\n",
    "[ 0.53838,0.32774  ],\r\n",
    "[ 0.4849, 0.26071  ],\r\n",
    "[ 0.37095,0.38809  ],\r\n",
    "[ 0.54527,0.63911  ],\r\n",
    "[ 0.32149,0.12007  ],\r\n",
    "[ 0.42216,0.61666  ],\r\n",
    "[ 0.10194,0.060408 ],\r\n",
    "[ 0.15254,0.2168   ],\r\n",
    "[ 0.45558,0.43769  ],\r\n",
    "[ 0.28488,0.52142  ],\r\n",
    "[ 0.27633,0.21264  ],\r\n",
    "[ 0.39748,0.31902  ],\r\n",
    "[ 0.5533, 1],\r\n",
    "[ 0.44274,0.59205  ],\r\n",
    "[ 0.85176,0.6612   ],\r\n",
    "[ 0.60436,0.86605  ],\r\n",
    "[ 0.68243,0.48301  ],\r\n",
    "[ 1,0.76815  ],\r\n",
    "[ 0.72989,0.8107   ],\r\n",
    "[ 0.67377,0.77975  ],\r\n",
    "[ 0.78761,0.58177  ],\r\n",
    "[ 0.71442,0.7668   ],\r\n",
    "[ 0.49379,0.54226  ],\r\n",
    "[ 0.78974,0.74233  ],\r\n",
    "[ 0.67905,0.60921  ],\r\n",
    "[ 0.6642, 0.72519  ],\r\n",
    "[ 0.79396,0.56789  ],\r\n",
    "[ 0.70758,0.76022  ],\r\n",
    "[ 0.59421,0.61857  ],\r\n",
    "[ 0.49364,0.56224  ],\r\n",
    "[ 0.77707,0.35025  ],\r\n",
    "[ 0.79785,0.76921  ],\r\n",
    "[ 0.70876,0.96764  ],\r\n",
    "[ 0.69176,0.60865  ],\r\n",
    "[ 0.66408,0.92075  ],\r\n",
    "[ 0.65973,0.66666  ],\r\n",
    "[ 0.64574,0.56845  ],\r\n",
    "[ 0.89639,0.7085   ],\r\n",
    "[ 0.85476,0.63167  ],\r\n",
    "[ 0.62091,0.80424  ],\r\n",
    "[ 0.79057,0.56108  ],\r\n",
    "[ 0.58935,0.71582  ],\r\n",
    "[ 0.56846,0.7406   ],\r\n",
    "[ 0.65912,0.71548  ],\r\n",
    "[ 0.70938,0.74041  ],\r\n",
    "[ 0.59154,0.62927  ],\r\n",
    "[ 0.45829,0.4641   ],\r\n",
    "[ 0.79982,0.74847  ],\r\n",
    "[ 0.60974,0.54757  ],\r\n",
    "[ 0.68127,0.86985  ],\r\n",
    "[ 0.76694,0.64736  ],\r\n",
    "[ 0.69048,0.83058  ],\r\n",
    "[ 0.68122,0.96541  ],\r\n",
    "[ 0.73229,0.64245  ],\r\n",
    "[ 0.76145,0.60138  ],\r\n",
    "[ 0.58985,0.86955  ],\r\n",
    "[ 0.73145,0.74516  ],\r\n",
    "[ 0.77029,0.7014   ],\r\n",
    "[ 0.73156,0.71782  ],\r\n",
    "[ 0.44556,0.57991  ],\r\n",
    "[ 0.85275,0.85987  ],\r\n",
    "[ 0.51912,0.62359  ]]\r\n",
    "\r\n",
    "_y = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\r\n",
    "\r\n",
    "_W = [[0.37454012],[0.95071431]]\r\n",
    "_b = 1.731993941811405\r\n",
    "\r\n",
    "perceptronStep(_X, _y, _W, _b, 0.01)\r\n",
    "\r\n",
    "# This function runs the perceptron algorithm repeatedly on the dataset,\r\n",
    "# and returns a few of the boundary lines obtained in the iterations,\r\n",
    "# for plotting purposes.\r\n",
    "# Feel free to play with the learning rate and the num_epochs,\r\n",
    "# and see your results plotted below.\r\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\r\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\r\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\r\n",
    "    W = np.array(np.random.rand(2,1))\r\n",
    "    b = np.random.rand(1)[0] + x_max\r\n",
    "    # These are the solution lines that get plotted below.\r\n",
    "    boundary_lines = []\r\n",
    "    for i in range(num_epochs):\r\n",
    "        # In each epoch, we apply the perceptron step.\r\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\r\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\r\n",
    "    return boundary_lines\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Non-linear Regions\r\n",
    "data can't be separated with a line\r\n",
    "\r\n",
    "curve ?\r\n",
    "\r\n",
    "### Error Functions\r\n",
    "...it tells us how are we are from the goal*\r\n",
    "\r\n",
    "### Log-loss Error Function\r\n",
    "\r\n",
    "our error should be continuous\r\n",
    "\r\n",
    "sigmoid(x) = 1/(1+e-x)\r\n",
    "where e = 2.71828\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "import numpy as np\r\n",
    "import math\r\n",
    "# Write a function that takes as input a list of numbers, and returns\r\n",
    "# the list of values given by the softmax function.\r\n",
    "def softmax(L):\r\n",
    "    result = []\r\n",
    "    d = [math.exp(i) for i in L]\r\n",
    "    for i in L:\r\n",
    "        result.append(math.exp(i)/sum(d))\r\n",
    "    \r\n",
    "    return result\r\n",
    "\r\n",
    "print(softmax([5,6,7]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.09003057317038046, 0.24472847105479764, 0.6652409557748219]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### One-Hot Encoding\r\n",
    "turning categories or classes into a number\r\n",
    "\r\n",
    "### Maximum Likelihood\r\n",
    "the product of all probabilities\r\n",
    "\r\n",
    "can the error function also be the probabilities?\r\n",
    "\r\n",
    "### Cross Entropy\r\n",
    "-log(x1) - log(x2) - log(n)\r\n",
    "\r\n",
    "...the highest number the more errors the model has\r\n",
    "\r\n",
    "### cross Entropy\r\n",
    "\r\n",
    "Y is a list of results\r\n",
    "P is the probability for each answer\r\n",
    "\r\n",
    "-np.sum(Y * np.log(P) + (1 - Y) * np.log(1 - P))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "# Write a function that takes as input two lists Y, P,\r\n",
    "# and returns the float corresponding to their cross-entropy.\r\n",
    "def cross_entropy(Y, P):\r\n",
    "    import math\r\n",
    "    \r\n",
    "    Y = np.float_(Y)\r\n",
    "    P = np.float_(P)\r\n",
    "    \r\n",
    "    # return -np.sum(Y * np.log(P) + (1 - Y) * np.log(1 - P))\r\n",
    "    \r\n",
    "    sum = 0\r\n",
    "    for i in range(len(P)):\r\n",
    "        x = (Y[i] * math.log(P[i])) + (1 - Y[i]) * math.log(1-P[i])\r\n",
    "        sum += x\r\n",
    "    return -sum"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-Class Cross Entropy\r\n",
    "\r\n",
    "- np.sum(np.sum(Y * np.log(P)))\r\n",
    "\r\n",
    "\r\n",
    "Error = -(1-Y)(np.log(1-y_hat))-Y*np.log(y_hat)\r\n",
    "ErrorFunction = -(1/M)* np.sum((1-Y)(np.log(1-y_hat)+Y*np.log(y_hat)))\r\n",
    "\r\n",
    "substitute with the weights of the models\r\n",
    "\r\n",
    "-(1/M)* np.sum((1-Y)(np.log(1- np.sum(W*X + b) )+Y*np.log(np.sum(W*X + b))))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Descent\r\n",
    "\r\n",
    "y_hat = sigmoid(Wx+b)\r\n",
    "y_hat = sigmoid(Wx+Wx+Wx ... +b)\r\n",
    "â©—E = (AE/AW, ... , AE/Ab)\r\n",
    "alpha = 0.1 (learning rate)\r\n",
    "w1 = W - Î± AE/AW\r\n",
    "b1 = b -Î± AE/AB\r\n",
    "y_hat = Ïƒ(W1*x+b1)\r\n",
    "\r\n",
    "\r\n",
    "Ïƒâ€²(x) = Ïƒ(x)(1âˆ’Ïƒ(x))\r\n",
    "\r\n",
    "E=âˆ’ (1/m)â€‹ âˆ‘ [i=1m] â€‹(yi â€‹ln( yiâ€‹^â€‹)+(1âˆ’yiâ€‹)ln(1âˆ’ yiâ€‹^â€‹))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "âˆ‡E=âˆ’(yâˆ’ y^â€‹)(x 1â€‹,â€¦,x n,1).\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### nonlinear models\r\n",
    "#### Neural Network Architecture\r\n",
    "\r\n",
    "we can combine 2 or more linear models to create a nonlinear model.\r\n",
    "each linear model can have weights and biases\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Implement the following functions\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# Activation (sigmoid) function\r\n",
    "def sigmoid(x):\r\n",
    "    return 1/(1+np.exp(-x))\r\n",
    "\r\n",
    "# Output (prediction) formula\r\n",
    "def output_formula(features, weights, bias):\r\n",
    "    return sigmoid(np.dot(features,weights)+bias)\r\n",
    "\r\n",
    "# Error (log-loss) formula\r\n",
    "def error_formula(y, output):\r\n",
    "    return -y * np.log(output) - (1-y)*np.log(1-output)\r\n",
    "\r\n",
    "# Gradient descent step\r\n",
    "def update_weights(x, y, weights, bias, learnrate):\r\n",
    "    output = output_formula(x, weights, bias)\r\n",
    "    d_error = y - output # difference between the predicted and the output\r\n",
    "    weights += learnrate * d_error * x #updates the weight\r\n",
    "    bias += learnrate * d_error #updates the bias\r\n",
    "    return weights, bias #returns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "\r\n",
    "w1 = 5\r\n",
    "w2 = 4\r\n",
    "b = -3\r\n",
    "\r\n",
    "r = w1*0.4 + w2*0.6 + b\r\n",
    "print(sigmoid(r))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8021838885585818\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### neural network\r\n",
    "\r\n",
    "* input layer (first layer)\r\n",
    "* hidden layer (middle layers)\r\n",
    "* output layer (last layer)\r\n",
    "\r\n",
    "### back propagation\r\n",
    "modifying the weights and biases when he model is wrong\r\n",
    "\r\n",
    "### chain rule\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "![](https://video.udacity-data.com/topher/2017/September/59b6ffad_sigmoid-derivative/sigmoid-derivative.gif)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## part 2\r\n",
    "Gradient Decent\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "mean squared error\r\n",
    "E= 1/2 âˆ‘â€‹ âˆ‘â€‹[y âˆ’ y^_hatâ€‹]^2\r\n",
    "\r\n",
    "\r\n",
    "y - y_hat\r\n",
    "^the difference between the solution, and what we predicted\r\n",
    "\r\n",
    "(y-y_hat)^2\r\n",
    "now we square it...\r\n",
    "\r\n",
    "SUM((y-y_hat)^2)\r\n",
    "but we want all the error for all the datasets\r\n",
    "so we will sum those all up\r\n",
    "\r\n",
    "1/2 (SUM((y-y_hat)^2))\r\n",
    "now divide it by half\r\n",
    "\r\n",
    "1/2 (SUM((y-(function(SUM(W*X)))^2))\r\n",
    "y_hat can be subsitued for the weights and inputs\r\n",
    "\r\n",
    "https://www.youtube.com/watch?v=7sxA5Ap8AWM&t=137s\r\n",
    "\r\n",
    "SSE high ..  bad predictions\r\n",
    "SSE low .. good predictions\r\n",
    "\r\n",
    "error term\r\n",
    "~~delta = (y-y_hat)f(h)~~\r\n",
    "error_term = error * output * (1 - output)\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "def sigmoid(x):\r\n",
    "    \"\"\"\r\n",
    "    Calculate sigmoid\r\n",
    "    \"\"\"\r\n",
    "    return 1/(1+np.exp(-x))\r\n",
    "\r\n",
    "def sigmoid_prime(x):\r\n",
    "    \"\"\"\r\n",
    "    # Derivative of the sigmoid function\r\n",
    "    \"\"\"\r\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\r\n",
    "\r\n",
    "learnrate = 0.5\r\n",
    "x = np.array([1, 2, 3, 4])\r\n",
    "y = np.array(0.5)\r\n",
    "\r\n",
    "# Initial weights\r\n",
    "w = np.array([0.5, -0.5, 0.3, 0.1])\r\n",
    "\r\n",
    "### Calculate one gradient descent step for each weight\r\n",
    "### Note: Some steps have been consolidated, so there are\r\n",
    "###       fewer variable names than in the above sample code\r\n",
    "\r\n",
    "# TODO: Calculate the node's linear combination of inputs and weights\r\n",
    "h = np.dot(w,x)\r\n",
    "\r\n",
    "# TODO: Calculate output of neural network\r\n",
    "nn_output = sigmoid(h)\r\n",
    "\r\n",
    "# TODO: Calculate error of neural network\r\n",
    "error = y[0] - nn_output\r\n",
    "\r\n",
    "# TODO: Calculate the error term\r\n",
    "#       Remember, this requires the output gradient, which we haven't\r\n",
    "#       specifically added a variable for.\r\n",
    "error_term = error * sigmoid_prime(h)\r\n",
    "\r\n",
    "# TODO: Calculate change in weights\r\n",
    "del_w = learnrate * error_term * x\r\n",
    "\r\n",
    "print('Neural Network output:')\r\n",
    "print(nn_output)\r\n",
    "print('Amount of Error:')\r\n",
    "print(error)\r\n",
    "print('Change in Weights:')\r\n",
    "print(del_w)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementing gradient descent\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "np.dot([1,2,3],[1,2,3])\r\n",
    "# np.matmul([1,2,3],[1,2,3])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "from data_prep import features, targets, features_test, targets_test\r\n",
    "\r\n",
    "\r\n",
    "def sigmoid(x):\r\n",
    "    \"\"\"\r\n",
    "    Calculate sigmoid\r\n",
    "    \"\"\"\r\n",
    "    return 1 / (1 + np.exp(-x))\r\n",
    "\r\n",
    "# TODO: We haven't provided the sigmoid_prime function like we did in\r\n",
    "#       the previous lesson to encourage you to come up with a more\r\n",
    "#       efficient solution. If you need a hint, check out the comments\r\n",
    "#       in solution.py from the previous lecture.\r\n",
    "def sigmoid_prime(x):\r\n",
    "    \"\"\"\r\n",
    "    # Derivative of the sigmoid function\r\n",
    "    \"\"\"\r\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\r\n",
    "    \r\n",
    "# Use to same seed to make debugging easier\r\n",
    "np.random.seed(42)\r\n",
    "\r\n",
    "n_records, n_features = features.shape\r\n",
    "last_loss = None\r\n",
    "\r\n",
    "# Initialize weights\r\n",
    "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\r\n",
    "\r\n",
    "# Neural Network hyperparameters\r\n",
    "epochs = 1000\r\n",
    "learnrate = 0.5\r\n",
    "\r\n",
    "for e in range(epochs):\r\n",
    "    del_w = np.zeros(weights.shape)\r\n",
    "    for x, y in zip(features.values, targets):\r\n",
    "        # Loop through all records, x is the input, y is the target\r\n",
    "\r\n",
    "        # Note: We haven't included the h variable from the previous\r\n",
    "        #       lesson. You can add it if you want, or you can calculate\r\n",
    "        #       the h together with the output\r\n",
    "\r\n",
    "        # TODO: Calculate the output\r\n",
    "        output = sigmoid(np.dot(x,weights))\r\n",
    "\r\n",
    "        # TODO: Calculate the error\r\n",
    "        error = y-output\r\n",
    "\r\n",
    "        # TODO: Calculate the error term\r\n",
    "        error_term = error * output * (1 - output)\r\n",
    "\r\n",
    "        # TODO: Calculate the change in weights for this sample\r\n",
    "        #       and add it to the total weight change\r\n",
    "        del_w += error_term * x\r\n",
    "\r\n",
    "    # TODO: Update weights using the learning rate and the average change in weights\r\n",
    "    weights += learnrate * del_w / n_records\r\n",
    "\r\n",
    "    # Printing out the mean square error on the training set\r\n",
    "    if e % (epochs / 10) == 0:\r\n",
    "        out = sigmoid(np.dot(features, weights))\r\n",
    "        loss = np.mean((out - targets) ** 2)\r\n",
    "        if last_loss and last_loss < loss:\r\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\r\n",
    "        else:\r\n",
    "            print(\"Train loss: \", loss)\r\n",
    "        last_loss = loss\r\n",
    "\r\n",
    "\r\n",
    "# Calculate accuracy on test data\r\n",
    "tes_out = sigmoid(np.dot(features_test, weights))\r\n",
    "predictions = tes_out > 0.5\r\n",
    "accuracy = np.mean(predictions == targets_test)\r\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Backpropagation\r\n",
    "\r\n",
    "the error for units is proportional to the error in the output layer times the weight between the units\r\n",
    "\r\n",
    "\r\n",
    "[error in output layer] * [weights between the units]\r\n",
    "\r\n",
    "\r\n",
    "the error from the entire network\r\n",
    "times the weight of that node\r\n",
    "...is the error for that node.\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "def sigmoid(x):\r\n",
    "    \"\"\"\r\n",
    "    Calculate sigmoid\r\n",
    "    \"\"\"\r\n",
    "    return 1 / (1 + np.exp(-x))\r\n",
    "\r\n",
    "\r\n",
    "x = np.array([0.5, 0.1, -0.2])\r\n",
    "target = 0.6\r\n",
    "learnrate = 0.5\r\n",
    "\r\n",
    "weights_input_hidden = np.array([[0.5, -0.6],\r\n",
    "                                 [0.1, -0.2],\r\n",
    "                                 [0.1, 0.7]])\r\n",
    "\r\n",
    "weights_hidden_output = np.array([0.1, -0.3])\r\n",
    "\r\n",
    "## Forward pass\r\n",
    "hidden_layer_input = np.dot(x, weights_input_hidden)\r\n",
    "hidden_layer_output = sigmoid(hidden_layer_input)\r\n",
    "\r\n",
    "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\r\n",
    "output = sigmoid(output_layer_in)\r\n",
    "\r\n",
    "## Backwards pass\r\n",
    "## TODO: Calculate output error\r\n",
    "error = target - output\r\n",
    "\r\n",
    "# TODO: Calculate error term for output layer\r\n",
    "output_error_term = error * output * (1 - output)\r\n",
    "\r\n",
    "# TODO: Calculate error term for hidden layer\r\n",
    "hidden_error_term = np.dot(output_error_term,weights_hidden_output) * hidden_layer_output * (1-hidden_layer_output)\r\n",
    "\r\n",
    "# TODO: Calculate change in weights for hidden layer to output layer\r\n",
    "delta_w_h_o = learnrate * output_error_term * hidden_layer_output\r\n",
    "\r\n",
    "# TODO: Calculate change in weights for input layer to hidden layer\r\n",
    "delta_w_i_h = learnrate * hidden_error_term * x[:, None]\r\n",
    "\r\n",
    "\r\n",
    "print('Change in weights for hidden layer to output layer:')\r\n",
    "print(delta_w_h_o)\r\n",
    "print('Change in weights for input layer to hidden layer:')\r\n",
    "print(delta_w_i_h)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "from data_prep import features, targets, features_test, targets_test\r\n",
    "\r\n",
    "np.random.seed(21)\r\n",
    "\r\n",
    "def sigmoid(x):\r\n",
    "    \"\"\"\r\n",
    "    Calculate sigmoid\r\n",
    "    \"\"\"\r\n",
    "    return 1 / (1 + np.exp(-x))\r\n",
    "\r\n",
    "\r\n",
    "# Hyperparameters\r\n",
    "n_hidden = 2  # number of hidden units\r\n",
    "epochs = 900\r\n",
    "learnrate = 0.005\r\n",
    "\r\n",
    "n_records, n_features = features.shape\r\n",
    "last_loss = None\r\n",
    "# Initialize weights\r\n",
    "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5,\r\n",
    "                                        size=(n_features, n_hidden))\r\n",
    "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5,\r\n",
    "                                         size=n_hidden)\r\n",
    "\r\n",
    "for e in range(epochs):\r\n",
    "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\r\n",
    "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\r\n",
    "    for x, y in zip(features.values, targets):\r\n",
    "        ## Forward pass ##\r\n",
    "        # TODO: Calculate the output\r\n",
    "        hidden_input = np.dot(x, weights_input_hidden)\r\n",
    "        hidden_output = sigmoid(hidden_input)\r\n",
    "\r\n",
    "        output = sigmoid(np.dot(hidden_output,\r\n",
    "                                weights_hidden_output))\r\n",
    "\r\n",
    "        ## Backward pass ##\r\n",
    "        # TODO: Calculate the network's prediction error\r\n",
    "        error = y - output\r\n",
    "\r\n",
    "        # TODO: Calculate error term for the output unit\r\n",
    "        output_error_term = error * output * (1 - output)\r\n",
    "\r\n",
    "        ## propagate errors to hidden layer\r\n",
    "\r\n",
    "        # TODO: Calculate the hidden layer's contribution to the error\r\n",
    "        hidden_error = np.dot(output_error_term, weights_hidden_output)\r\n",
    "\r\n",
    "        # TODO: Calculate the error term for the hidden layer\r\n",
    "        hidden_error_term = hidden_error * hidden_output * (1 - hidden_output)\r\n",
    "\r\n",
    "        # TODO: Update the change in weights\r\n",
    "        del_w_hidden_output += output_error_term * hidden_output\r\n",
    "        del_w_input_hidden += hidden_error_term * x[:, None]\r\n",
    "\r\n",
    "    # TODO: Update weights\r\n",
    "    weights_input_hidden += learnrate * del_w_input_hidden / n_records\r\n",
    "    weights_hidden_output += learnrate * del_w_hidden_output / n_records\r\n",
    "\r\n",
    "    # Printing out the mean square error on the training set\r\n",
    "    if e % (epochs / 10) == 0:\r\n",
    "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\r\n",
    "        out = sigmoid(np.dot(hidden_output,\r\n",
    "                             weights_hidden_output))\r\n",
    "        loss = np.mean((out - targets) ** 2)\r\n",
    "\r\n",
    "        if last_loss and last_loss < loss:\r\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\r\n",
    "        else:\r\n",
    "            print(\"Train loss: \", loss)\r\n",
    "        last_loss = loss\r\n",
    "\r\n",
    "# Calculate accuracy on test data\r\n",
    "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\r\n",
    "out = sigmoid(np.dot(hidden, weights_hidden_output))\r\n",
    "predictions = out > 0.5\r\n",
    "accuracy = np.mean(predictions == targets_test)\r\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "underfitted model:\r\n",
    "a model that has not been trained enough\r\n",
    "\r\n",
    "overfitted model:\r\n",
    "a model that has been trainned too much\r\n",
    "and cannot generalize\r\n",
    "\r\n",
    "just right:\r\n",
    "in the middle\r\n",
    "\r\n",
    "***model complexity graph***\r\n",
    "\r\n",
    "...\r\n",
    "\r\n",
    "![video](https://www.youtube.com/watch?v=NnS0FJyVcDQ)\r\n",
    "\r\n",
    "error = sigmoid(W1+W2)\r\n",
    "![video](https://www.youtube.com/watch?v=ndYnUrx8xvs)\r\n",
    "\r\n",
    "error_function\r\n",
    "-1/2 sum(1-y_hat)* log(1-y_hat) + y*log(y_hat) + lamda(|w1|+|w2|+...|wn|))\r\n",
    "-1/2 sum(1-y_hat)* log(1-y_hat) + y*log(y_hat) + lamda(w1^2+w2^2+...wn^2))\r\n",
    "\r\n",
    "L1 vs L2 Regulation\r\n",
    "\r\n",
    "L1\r\n",
    "(1,0,0,1,0)\r\n",
    "\r\n",
    "L2\r\n",
    "(0.5,0.3,-0.2,0.4,0.1)\r\n",
    "\r\n",
    "L2 has better trained models\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "![video](https://www.youtube.com/watch?v=Ty6K6YiGdBs)\r\n",
    "\r\n",
    "\r\n",
    "Dropout:\r\n",
    "randomly turning off nodes\r\n",
    "...allowing other nodes to get strong\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "![video](https://www.youtube.com/watch?v=gF_sW_nY-xw)\r\n",
    "![video](https://www.youtube.com/watch?v=idyBBCzXiqg)\r\n",
    "![video](https://www.youtube.com/watch?v=W_JJm_5syFw)\r\n",
    "\r\n",
    "activation functions\r\n",
    "![video](https://www.youtube.com/watch?v=kA-1vUt6cvQ)\r\n",
    "Sigmoid  \r\n",
    "Hyperbolic  \r\n",
    "ReLu  \r\n",
    "softReLu  \r\n",
    "\r\n",
    "\r\n",
    "![video](https://www.youtube.com/watch?v=2p58rVgqsgo)\r\n",
    "\r\n",
    "* Stochastic Gradient Descent  \r\n",
    "split the data into batches  \r\n",
    "for each batch  \r\n",
    "    calculate the error and the gradient\r\n",
    "\r\n",
    "\r\n",
    "![video](https://www.youtube.com/watch?v=TwJ8aSZoh2U)\r\n",
    "* Learning Rate Decay\r\n",
    "decrease the learning rate over time\r\n",
    "\r\n",
    "\r\n",
    "![video](https://www.youtube.com/watch?v=r-rYz_PEWC8)\r\n",
    "momentum\r\n",
    "the previous step matters, but the ones before that decrease in important.\r\n",
    "\r\n",
    "step(n), step(n-1)*beta, step(n-2)*beta^2, step(n-3)*beta^3\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## part 3\r\n",
    "Training Neural Networks\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## part 4\r\n",
    "GPU workspaces Demo\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#workspace utils\r\n",
    "import signal\r\n",
    "\r\n",
    "from contextlib import contextmanager\r\n",
    "\r\n",
    "import requests\r\n",
    "\r\n",
    "\r\n",
    "DELAY = INTERVAL = 4 * 60  # interval time in seconds\r\n",
    "MIN_DELAY = MIN_INTERVAL = 2 * 60\r\n",
    "KEEPALIVE_URL = \"https://nebula.udacity.com/api/v1/remote/keep-alive\"\r\n",
    "TOKEN_URL = \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\"\r\n",
    "TOKEN_HEADERS = {\"Metadata-Flavor\":\"Google\"}\r\n",
    "\r\n",
    "\r\n",
    "def _request_handler(headers):\r\n",
    "    def _handler(signum, frame):\r\n",
    "        requests.request(\"POST\", KEEPALIVE_URL, headers=headers)\r\n",
    "    return _handler\r\n",
    "\r\n",
    "\r\n",
    "@contextmanager\r\n",
    "def active_session(delay=DELAY, interval=INTERVAL):\r\n",
    "    \"\"\"\r\n",
    "    Example:\r\n",
    "\r\n",
    "    from workspace_utils import active session\r\n",
    "\r\n",
    "    with active_session():\r\n",
    "        # do long-running work here\r\n",
    "    \"\"\"\r\n",
    "    token = requests.request(\"GET\", TOKEN_URL, headers=TOKEN_HEADERS).text\r\n",
    "    headers = {'Authorization': \"STAR \" + token}\r\n",
    "    delay = max(delay, MIN_DELAY)\r\n",
    "    interval = max(interval, MIN_INTERVAL)\r\n",
    "    original_handler = signal.getsignal(signal.SIGALRM)\r\n",
    "    try:\r\n",
    "        signal.signal(signal.SIGALRM, _request_handler(headers))\r\n",
    "        signal.setitimer(signal.ITIMER_REAL, delay, interval)\r\n",
    "        yield\r\n",
    "    finally:\r\n",
    "        signal.signal(signal.SIGALRM, original_handler)\r\n",
    "        signal.setitimer(signal.ITIMER_REAL, 0)\r\n",
    "\r\n",
    "\r\n",
    "def keep_awake(iterable, delay=DELAY, interval=INTERVAL):\r\n",
    "    \"\"\"\r\n",
    "    Example:\r\n",
    "\r\n",
    "    from workspace_utils import keep_awake\r\n",
    "\r\n",
    "    for i in keep_awake(range(5)):\r\n",
    "        # do iteration with lots of work here\r\n",
    "    \"\"\"\r\n",
    "    with active_session(delay, interval): yield from iterable"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#keep_awake\r\n",
    "from workspace_utils import keep_awake\r\n",
    "\r\n",
    "for i in keep_awake(range(5)):  #anything that happens inside this loop will keep the workspace active\r\n",
    "    # do iteration with lots of work here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#active_session\r\n",
    "from workspace_utils import active_session\r\n",
    "\r\n",
    "with active_session():\r\n",
    "    # do long-running work here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "reset data\r\n",
    "this delete your data and restore the defaults\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 5\r\n",
    "Sentment Analysis\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentment Analysis 1..15"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "![video](https://www.youtube.com/watch?v=ltO71Bm8b3M)\r\n",
    "\r\n",
    "![video](https://www.youtube.com/watch?v=da1I0mea1jQ)\r\n",
    "\r\n",
    "take in text  \r\n",
    "and figure out if it's positive or negative\r\n",
    "\r\n",
    "\r\n",
    "github repo  \r\n",
    "https://github.com/udacity/deep-learning-v2-pytorch\r\n",
    "\r\n",
    "workspace  \r\n",
    "https://classroom.udacity.com/nanodegrees/nd101/parts/644c0fc9-7889-4622-aa2e-a339ba9e3268/modules/61f4fe0c-9035-42ca-b576-65865c4f0924/lessons/47d78191-5dea-420f-8723-f5f3fd7a148a/concepts/3cc08c9f-50e9-4650-a67e-179a3cbb9dcf\r\n",
    "\r\n",
    "#### parts\r\n",
    "Sentiment_Classification_Projects.ipynb - a notebook you will use to following along and work on lesson mini projects.  \r\n",
    "Sentiment_Classification_Solutions.ipynb - a notebook that includes Andrewâ€™s solutions to the lesson projects, which you can use for reference  \r\n",
    "A notebook for the solution for each mini project.  \r\n",
    "reviews.txt - a collection of 25 thousand movie reviews  \r\n",
    "labels.txt - positive/negative sentiment labels for the associated reviews in reviews.txt  \r\n",
    "\r\n",
    "\r\n",
    "link to notebook   \r\n",
    "https://classroom.udacity.com/nanodegrees/nd101/parts/644c0fc9-7889-4622-aa2e-a339ba9e3268/modules/61f4fe0c-9035-42ca-b576-65865c4f0924/lessons/47d78191-5dea-420f-8723-f5f3fd7a148a/concepts/3cc08c9f-50e9-4650-a67e-179a3cbb9dcf"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### better initalizing\r\n",
    "\r\n",
    "initalize between [-y,y]\r\n",
    "y = 1/math.sqrt(n)\r\n",
    "n = number of inputs in a given layer\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### reducing noise\r\n",
    "\r\n",
    "![video](https://www.youtube.com/watch?v=ubqhh4Iv7O4)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "# a = np.array([0,1,0,1,0,1,0,1,0])\r\n",
    "# m = a>0\r\n",
    "# b  = a[a>0]\r\n",
    "\r\n",
    "# print(b)\r\n",
    "# print(m)\r\n",
    "\r\n",
    "# for index,i in enumerate(m):\r\n",
    "#     print(index,i)\r\n",
    "\r\n",
    "\r\n",
    "a = np.array([0,1,0,1,0,1,0,1,0])\r\n",
    "b = np.array([0,1,0,1,0,1,0,1,0])\r\n",
    "\r\n",
    "x = a.dot(b)\r\n",
    "print(x.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "()\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit (system)"
  },
  "interpreter": {
   "hash": "509e899b051dc9520d2fe7a9d709ed1b5a930f9df2878192749797afadf4e6af"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}